{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3DMNN\n",
    "#### EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object files_in_subdirs at 0x7f87649df728>\n",
      "6778 pclouds were loaded. They belong in 1 shape-classes.\n",
      "WARNING:tensorflow:From /home/viktorv/.conda/envs/3dmnn_cu9/lib/python3.6/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "INFO:tensorflow:Restoring parameters from /home/viktorv/Projects/3DMNN/data/point_cloud_sampled/data/single_class_ae/models.ckpt-70\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/home/viktorv/Projects/3DMNN/main/models/latent_space/src\")\n",
    "\n",
    "from classes.autoencoder import Configuration as Conf\n",
    "from classes.gan import ConfigurationGAN as ConfGAN\n",
    "from classes.pointnet_ae import PointNetAutoEncoder\n",
    "\n",
    "from utils.templates import innofair_architecture\n",
    "from utils.templates import autoencoder_paper, default_train_params\n",
    "from utils.io import obj_wrapper, generate_mitsuba_xml\n",
    "\n",
    "from utils.io import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "\n",
    "from utils.utils import reset_tf_graph\n",
    "from classes.latent_gan import LatentGAN\n",
    "\n",
    "top_out_dir = '/home/viktorv/Projects/3DMNN/data/point_cloud_sampled/data'          # Use to save Neural-Net check-points etc.\n",
    "top_in_dir = '/home/viktorv/Projects/3DMNN/data/point_cloud_sampled/data/shape_net_core_uniform_samples_2048/' # Top-dir of where point-clouds are stored.\n",
    "\n",
    "experiment_name = 'single_class_ae'\n",
    "n_pc_points = 2048                # Number of points per model.\n",
    "bneck_size = 128                  # Bottleneck-AE size\n",
    "ae_loss = 'emd'                   # Loss to optimize: 'emd' or 'chamfer'\n",
    "\n",
    "#class_name = input('Give me the class name (e.g. \"chair\"): ').lower()\n",
    "class_name = \"chair\"\n",
    "\n",
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir, syn_id)\n",
    "\n",
    "all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)\n",
    "train_dir = create_dir(osp.join(top_out_dir, experiment_name))\n",
    "\n",
    "\n",
    "# train_params = default_train_params()\n",
    "\n",
    "# encoder, decoder, enc_args, dec_args = autoencoder_paper(n_pc_points, bneck_size)\n",
    "\n",
    "\n",
    "# conf = Conf(\n",
    "#     n_input = [n_pc_points, 3],\n",
    "#     loss = ae_loss,\n",
    "#     training_epochs = 10,\n",
    "#     batch_size = train_params['batch_size'],\n",
    "#     denoising = train_params['denoising'],\n",
    "#     learning_rate = train_params['learning_rate'],\n",
    "#     train_dir = train_dir,\n",
    "#     loss_display_step = train_params['loss_display_step'],\n",
    "#     saver_step = train_params['saver_step'],\n",
    "#     z_rotate = train_params['z_rotate'],\n",
    "#     encoder = encoder,\n",
    "#     decoder = decoder,\n",
    "#     encoder_args = enc_args,\n",
    "#     decoder_args = dec_args\n",
    "# )\n",
    "# conf.experiment_name = experiment_name\n",
    "# conf.held_out_step = 5   # How often to evaluate/print out loss on \n",
    "#                          # held_out data (if they are provided in ae.train() ).\n",
    "# conf.save(osp.join(train_dir, 'configuration'))\n",
    "\n",
    "# reset_tf_graph()\n",
    "# ae = PointNetAutoEncoder(conf.experiment_name, conf)\n",
    "\n",
    "# buf_size = 1 # Make 'training_stats' file to flush each output line regarding training.\n",
    "# fout = open(osp.join(conf.train_dir, 'train_stats.txt'), 'a', buf_size)\n",
    "# train_stats = ae.train(all_pc_data, conf, log_file=fout)\n",
    "# fout.close()\n",
    "\n",
    "# REUSE\n",
    "\n",
    "conf = Conf.load(train_dir + \"/configuration\")\n",
    "conf.encoder_args['verbose'] = False\n",
    "conf.decoder_args['verbose'] = False\n",
    "\n",
    "reset_tf_graph()\n",
    "\n",
    "ae = PointNetAutoEncoder(conf.experiment_name, conf)\n",
    "ae.restore_model(conf.train_dir, 70, verbose=False)\n",
    "\n",
    "#END REUSE\n",
    "\n",
    "# buf_size = 1 # Make 'training_stats' file to flush each output line regarding training.\n",
    "# fout = open(osp.join(conf.train_dir, 'train_stats.txt'), 'a', buf_size)\n",
    "# train_stats = ae.train(all_pc_data, conf, log_file=fout)\n",
    "# fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained a simple point net auto encoder... Define reconstruct and interpolate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 3)\n",
      "Reconstruction item shape: (2048, 3)\n",
      "Reconstructed\n",
      "Reconstruction item shape: (2048, 3)\n",
      "Reconstructed\n",
      "Generating interpolations\n",
      "(1, 2048, 3)\n",
      "(1, 2048, 3)\n",
      "Interpolation Complete\n",
      "(62, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "print(all_pc_data.point_clouds[-1].shape)\n",
    "\n",
    "import random as rd\n",
    "\n",
    "from_int = rd.randint(0, 4000)\n",
    "to_int = rd.randint(0, 4000)\n",
    "\n",
    "reconstruction_from = np.asarray(ae.reconstruct(all_pc_data.point_clouds[from_int].reshape(1,2048,3)))\n",
    "reconstruction_to = np.asarray(ae.reconstruct(all_pc_data.point_clouds[to_int].reshape(1,2048,3)))\n",
    "\n",
    "#data for the latent gan\n",
    "latent_codes = ae.get_latent_codes(all_pc_data.point_clouds)\n",
    "\n",
    "def reconstruct_obj(reconstructions):\n",
    "    print(\"Reconstruction item shape:\", reconstructions[0].shape)\n",
    "    \n",
    "    for i, reconstruction in enumerate(reconstructions):\n",
    "        obj_wrapper(reconstruction, class_name, i)\n",
    "        \n",
    "    print(\"Reconstructed\")\n",
    "\n",
    "def interpolate(_from, _to, steps=10):\n",
    "    \n",
    "    print(\"Generating interpolations\")\n",
    "    print(_from.shape)\n",
    "    print(_to.shape)\n",
    "    \n",
    "    interpolations = ae.interpolate(_from, _to, steps)\n",
    "\n",
    "    for i, interpolation in enumerate(interpolations):\n",
    "        obj_wrapper(interpolation, class_name + \"_intr\", i)\n",
    "        generate_mitsuba_xml(interpolation, class_name, i, variation=False)\n",
    "        \n",
    "    print(\"Interpolation Complete\")\n",
    "    print(interpolations.shape)\n",
    "\n",
    "reconstruct_obj(reconstruction_from[0])\n",
    "reconstruct_obj(reconstruction_to[0])\n",
    "\n",
    "interpolate(reconstruction_from[0], reconstruction_to[0], steps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and Configure GAN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6778, 128)\n",
      "{'init_lr': 0.0001, 'lambda': 10, 'n_out': [128], 'noise_dim': 128, 'beta': 0.5, 'batch_size': 50, 'noise_params': {'mu': 0, 'sigma': 0.2}}\n",
      "Calculating initial GP...\n",
      "INFO:tensorflow:Restoring parameters from ./models_checkpoints/models.ckpt-1000\n",
      "Model restored in epoch 1000.\n"
     ]
    }
   ],
   "source": [
    "generator, discriminator, params = innofair_architecture(128)\n",
    "\n",
    "print(latent_codes.shape)\n",
    "print(params)\n",
    "# TODO:\n",
    "# 5. Implement Conditional GAN in the LGAN\n",
    "\n",
    "reset_tf_graph()\n",
    "\n",
    "\n",
    "gan = LatentGAN(experiment_name, params['init_lr'], params['lambda'], params['n_out'],\\\n",
    "                params['noise_dim'], discriminator, generator, beta=params['beta'])\n",
    "gan.restore_model(\"./models_checkpoints/\", 1000, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_syn_data = []\n",
    "train_stats = []\n",
    "n_epochs = 1000\n",
    "# # Train the GAN.\n",
    "# saver_step = np.hstack([np.array([1, 5, 10]), np.arange(50, n_epochs + 1, 50)])\n",
    "# latent_data = PointCloudDataSet(latent_codes)\n",
    "\n",
    "# gan.train(latent_data, params, n_epochs, \"./models_checkpoints/\", save_gan_model=True, \\\n",
    "#           saver_step=saver_step, train_stats=train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128)\n",
      "(10, 2048, 3)\n",
      "Reconstruction item shape: (2048, 3)\n",
      "Reconstructed\n"
     ]
    }
   ],
   "source": [
    "syn_latent_data = gan.generate(10, params[\"noise_params\"])\n",
    "print(syn_latent_data.shape)\n",
    "\n",
    "syn_data = []\n",
    "for vector in syn_latent_data:\n",
    "    syn_data.append(ae.decode(vector))\n",
    "    \n",
    "syn_data = np.asarray(syn_data).reshape((10,2048,3))\n",
    "print(syn_data.shape)\n",
    "\n",
    "reconstruct_obj(syn_data)\n",
    "for i, data in enumerate(syn_data):\n",
    "    generate_mitsuba_xml(data, class_name + \"_gen\", i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "### 1. Rewrite CONF Class to fit GANs - DONE\n",
    "### 2. Implement Discriminator, Generator for the simple LGAN - DONE\n",
    "### 3. Train\n",
    "### 4. Try to decode something generated\n",
    "### 5. Implement Conditional GAN in the LGAN \n",
    "### 6. Go to 3 and 4 again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DMNN",
   "language": "python",
   "name": "3dmnn_cu9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
