{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is really old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test nice\n"
     ]
    }
   ],
   "source": [
    "print(\"test nice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling3D, UpSampling2D\n",
    "from keras.layers import Conv3D, Conv2D, AveragePooling2D, AveragePooling3D, Dense, Dropout, LeakyReLU\n",
    "from keras.layers import MaxPooling2D, MaxPooling3D, Conv2DTranspose, Input\n",
    "from keras.layers.core import Flatten\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import utils\n",
    "print(\"Imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary Imports\n"
     ]
    }
   ],
   "source": [
    "import pywavefront as pw\n",
    "import numpy as np\n",
    "import os.path\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "\n",
    "ks._BACKEND = 'theano'\n",
    "ks.set_image_dim_ordering(\"th\")\n",
    "\n",
    "print(\"Secondary Imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress, step=0.001,string=\"\",loss=False):\n",
    "    #ignore this pls, pure bullshit, but it looks good in the terminal.\n",
    "    print(\"\\r\"+string+\" [{0}] {1}%\".format('#'*int(progress/10 if loss else progress/500), int(progress + 1 if loss else progress/50)), end=\"\")\n",
    "    time.sleep(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():  \n",
    "    if os.path.isfile('main/models/dcgan/dataArray.npy'):\n",
    "        print(\"Loading existing data...\")\n",
    "        data = np.load(open('main/models/dcgan/dataArray.npy', 'rb'))\n",
    "    else:\n",
    "        print(\"Loading data...\")  \n",
    "        data=[]\n",
    "        for i in range(0,5000):\n",
    "            directory =  '/home/viktorv/Projects/3DMNN/data/concept_processed/cube'+str(i)+'.obj00'\n",
    "            data.append((pw.ObjParser(pw.Wavefront(directory), directory).vertices))\n",
    "            update_progress(i)\n",
    "        #endfor\n",
    "        data = np.array(data)\n",
    "        data.dump(open('dataArray.npy', 'wb'))\n",
    "    #endif\n",
    "    # print(data.shape)\n",
    "    # data = data.reshape((data.shape[0], data.shape[1], data.shape[2], 1))\n",
    "    # data = np.resize(data.shape, (5000, 9025, 3)).reshape((5000, 95, 95, 3))\n",
    "    data = np.resize(data.shape, (5000, 9025, 3)).reshape((5000, 3, 95, 95))    \n",
    "    \n",
    "    print(data.shape)\n",
    "\n",
    "    print(\"Loading complete!\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model(_1d=False):\n",
    "    model = Sequential()\n",
    "    #TODO: Try 1D Input and Output, idk.\n",
    "    depth = 32\n",
    "    dropout_rate = 0.4\n",
    "\n",
    "    model.add(Dense(128, input_shape=(128,)))\n",
    "    model.add(Reshape((128,1,1), input_shape=(128,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))    \n",
    "\n",
    "    model.add(Conv2DTranspose(depth*8,(4,4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))   \n",
    "\n",
    "    model.add(Conv2DTranspose(depth*4,(4,4), strides=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv2DTranspose(depth*2,(4,4), strides=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2DTranspose(depth,(5,5), strides=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2DTranspose(int(depth/2), (5,5), strides=(2, 2)))    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(3,(3,3)))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model(_1d=False):\n",
    "    model = Sequential()\n",
    "\n",
    "    depth = 32\n",
    "    dropout_rate = 0.4\n",
    "\n",
    "    model.add(Conv2D(depth, (3,3), input_shape=(3, 95, 95,)))\n",
    "    model.add(BatchNormalization())  \n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(depth*2, (3,3)))\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(depth*4, (3,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Conv2D(depth*8, (3,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))    \n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(generator)    \n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, BATCH_SIZE, load=False):\n",
    "\n",
    "    X_train = load_data()\n",
    "\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "\n",
    "    #tbCallBack = TensorBoard(log_dir='graph', histogram_freq=5, write_graph=True, write_images=True)\n",
    "    #tbCallBack.set_model(generator)\n",
    "\n",
    "    if load:\n",
    "        generator.load_weights('main/models/dcgan/goodgenerator.h5')\n",
    "        discriminator.load_weights('main/models/dcgan/gooddiscriminator.h5')\n",
    "    \n",
    "    discriminator_on_generator = generator_containing_discriminator(generator, discriminator)\n",
    "\n",
    "    d_optim = SGD(lr=0.0002, momentum=0.7)\n",
    "    g_optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "    discriminator_on_generator.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "\n",
    "    noise = np.zeros((BATCH_SIZE, 128))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.normal(-1, 1, 128)\n",
    "\n",
    "            batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "\n",
    "            generated = generator.predict(noise, verbose=0)\n",
    "\n",
    "            X = np.concatenate((batch, generated))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.normal(-1, 1, 128)\n",
    "\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "\n",
    "            update_progress(index, loss=True, string=\"Epoch: %d Batch: %d Dloss: %f Gloss: %f\" % (epoch, index, d_loss, g_loss))\n",
    "\n",
    "            if epoch % 10 == 9:\n",
    "                generator.save_weights('main/models/dcgan/goodgenerator.h5', True)\n",
    "                discriminator.save_weights('main/models/dcgan/gooddiscriminator.h5', True)\n",
    "        print()\n",
    "\n",
    "\n",
    "def obj_wrapper(coords, name=\"object\"):\n",
    "    lines = \"\"\n",
    "    for i in range(0, len(coords)):\n",
    "        lines += \"v \" + str(coords[i,0]) + \" \" + str(coords[i,1]) + \" \" + str(coords[i,2]) + \" #\" + str(i + 1) + \"\\n\"\n",
    "    \n",
    "    return lines\n",
    "\n",
    "\n",
    "def generate(BATCH_SIZE,name=\"generated\"):\n",
    "    generator = generator_model()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "    generator.load_weights('main/models/dcgan/goodgenerator.h5')\n",
    "\n",
    "    noise = np.zeros((BATCH_SIZE, 128))\n",
    "    a = np.random.normal(-1, 1, 128)\n",
    "    b = np.random.normal(-1, 1, 128)\n",
    "    grad = (b - a) / BATCH_SIZE\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        noise[i, :] = np.random.normal(-1, 1, 128)\n",
    "\n",
    "    generated = generator.predict(noise)\n",
    "\n",
    "    for i, pointcloud in enumerate(generated):\n",
    "        pointcloud = pointcloud.reshape(9025, 3)\n",
    "        file = open('./main/models/dcgan/generated_data/%s%s.obj'%(name,i), \"w\")\n",
    "        file.write(obj_wrapper(pointcloud))\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Starting DCGAN.\n",
      "Loading existing data...\n",
      "(5000, 3, 95, 95)\n",
      "Loading complete!\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 93, 93)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 93, 93)        372       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 93, 93)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 93, 93)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 91, 91)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 91, 91)        364       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 91, 91)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 91, 91)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 89, 89)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 89, 89)       356       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128, 89, 89)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 89, 89)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 256, 87, 87)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256, 87, 87)       348       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256, 87, 87)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 87, 87)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1937664)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1937665   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,327,521\n",
      "Trainable params: 2,326,801\n",
      "Non-trainable params: 720\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 128, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 256, 4, 4)         524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256, 4, 4)         16        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 128, 10, 10)       524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128, 10, 10)       40        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128, 10, 10)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128, 10, 10)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 22, 22)        131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64, 22, 22)        88        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 22, 22)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64, 22, 22)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 32, 47, 47)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 47, 47)        188       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 47, 47)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32, 47, 47)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 16, 97, 97)        12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 97, 97)        388       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16, 97, 97)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 97, 97)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 95, 95)         435       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 95, 95)         0         \n",
      "=================================================================\n",
      "Total params: 1,261,811\n",
      "Trainable params: 1,261,451\n",
      "Non-trainable params: 360\n",
      "_________________________________________________________________\n",
      "Epoch: 0 Batch: 199 Dloss: 0.000861 Gloss: 0.000000 [###################] 200%\n",
      "Epoch: 1 Batch: 41 Dloss: 0.000668 Gloss: 0.000000 [####] 42%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fdc22a90463b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[*] Starting DCGAN.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dcgan>>epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-9ef24067f417>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, BATCH_SIZE, load)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/3DMNN/py-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/3DMNN/py-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/3DMNN/py-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/3DMNN/py-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"[*] Starting DCGAN.\")\n",
    "    train(1000, 25, False)\n",
    "    generate(10, name=\"dcgan>>epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-env",
   "language": "python",
   "name": "py-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
